"""add crontasks table

Revision ID: a79c4cec2442
Revises: 12e0994850cc
Create Date: 2025-08-11 00:19:06.589276

"""

import warnings
from typing import TYPE_CHECKING

import sqlalchemy as sa
from alembic import op
from advanced_alchemy.types import EncryptedString, EncryptedText, GUID, ORA_JSONB, DateTimeUTC, StoredObject, PasswordHash
from sqlalchemy import Text  # noqa: F401
from sqlalchemy.dialects import postgresql
if TYPE_CHECKING:
    from collections.abc import Sequence

__all__ = ["downgrade", "upgrade", "schema_upgrades", "schema_downgrades", "data_upgrades", "data_downgrades"]

sa.GUID = GUID
sa.DateTimeUTC = DateTimeUTC
sa.ORA_JSONB = ORA_JSONB
sa.EncryptedString = EncryptedString
sa.EncryptedText = EncryptedText
sa.StoredObject = StoredObject

# revision identifiers, used by Alembic.
revision = 'a79c4cec2442'
down_revision = '12e0994850cc'
branch_labels = None
depends_on = None


def upgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            schema_upgrades()
            data_upgrades()

def downgrade() -> None:
    with warnings.catch_warnings():
        warnings.filterwarnings("ignore", category=UserWarning)
        with op.get_context().autocommit_block():
            data_downgrades()
            schema_downgrades()

def schema_upgrades() -> None:
    """schema upgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('cron_tasks',
    sa.Column('id', sa.Integer(), nullable=False),
    sa.Column('name', sa.Text(), nullable=False),
    sa.Column('task_name', sa.Text(), nullable=False),
    sa.Column('args', sa.JSON(), nullable=False),
    sa.Column('kwargs', sa.JSON(), nullable=False),
    sa.Column('cron', sa.Text(), nullable=False),
    sa.Column('enabled', sa.Boolean(), nullable=False),
    sa.Column('jobid', sa.Integer(), nullable=True),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('name')
    )
    with op.batch_alter_table('taskiq_results', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('taskiq_results_task_id_idx'), postgresql_using='hash')

    op.drop_table('taskiq_results')
    op.drop_table('taskiq_messages')
    # ### end Alembic commands ###

def schema_downgrades() -> None:
    """schema downgrade migrations go here."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('taskiq_messages',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('task_id', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('task_name', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('message', sa.TEXT(), autoincrement=False, nullable=False),
    sa.Column('labels', postgresql.JSONB(astext_type=sa.Text()), autoincrement=False, nullable=False),
    sa.Column('created_at', postgresql.TIMESTAMP(timezone=True), server_default=sa.text('now()'), autoincrement=False, nullable=True),
    sa.PrimaryKeyConstraint('id', name=op.f('taskiq_messages_pkey'))
    )
    op.create_table('taskiq_results',
    sa.Column('task_id', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('result', postgresql.BYTEA(), autoincrement=False, nullable=True),
    sa.UniqueConstraint('task_id', name=op.f('taskiq_results_task_id_key'), postgresql_include=[], postgresql_nulls_not_distinct=False)
    )
    with op.batch_alter_table('taskiq_results', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('taskiq_results_task_id_idx'), ['task_id'], unique=False, postgresql_using='hash')

    op.drop_table('cron_tasks')
    # ### end Alembic commands ###

def data_upgrades() -> None:
    """Add any optional data upgrade migrations here!"""

def data_downgrades() -> None:
    """Add any optional data downgrade migrations here!"""
